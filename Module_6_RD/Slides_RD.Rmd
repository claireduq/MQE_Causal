---
title: "MQE: Economic Inference from Data:  \nModule 6: Regression Discontinuity"
author: "Claire Duquennois"
date: "6/9/2020"
header-includes:
   - \usepackage{bbm}
output:
  beamer_presentation: default
  pdf_document: default
  slidy_presentation: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=9, fig.height=5) 

library(dplyr)
library(ggplot2)
library(lfe)
library(stargazer)
```

## Regression discontinuity research designs

Introduced in other fields as far back as the 1960s.

Gain popularity in economics in the past 20 years or so as economists:

- increasingly focus on causal inference

- large administrative datasets became more widely available

When correctly applied, RD designs are very transparent in how they achieve causal identification which makes them very appealing. 

## Regression discontinuity research designs


RD designs leverage the researchers knowledge of a rule or policy that determines treatment. 

Identification comes from how some rules are applied in a fairly arbitrary way.

This arbitrary application generates randomness we can exploit to estimate causal effects. 

## The Set Up

Suppose that we want to estimate the effect of some binary treatment $D_i$ on an outcome $Y_i$. Using the potential outcomes framework:
$$
Y_i=D_iY_i(1)+(1-D_i)Y_i(0)
$$

Suppose $D_i$ is completely (or partially) determined by whether some predictor $X_i$ lies above or below a certain threshold, $c$. 

## The Set Up

The "running variable" $X_i$ need not be randomly assigned:

- $X_i$ is related to $Y_i$

- absent treatment, this relationship is smooth ($Y_i$ does not jump discontinuously as $X_i$ changes). 

$\Rightarrow$ any discontinuous change in $Y_i$ as $X_i$ crosses $c$ can thus be interpreted as a causal effect of $D_i$. 

## Where to find RD setups?

Often from administrative situations in which units are assigned a program, treatment or award based on a numerical index being above or below a certain threshold.

## Where to find RD setups?

Examples:

- A politician may be elected if and only if the differential between the vote share that she receives and the vote share that her opponent receives exceeds 0.

- A student may be assigned to summer school if and only if his performance on a combination of tests falls below a certain threshold. 

- A toxic waste site may receive cleanup funds if and only if it's hazard rating falls above a certain level. 

## Why does RD work?

The idea:

- Units whose indices $X$ lie directly below the threshold $c$ are considered to be comparable to individuals or units whose indices $X$ lie directly above the threshold $c$.

- We can estimate the treatment effect by taking a difference in mean outcomes for units directly above the threshold and units directly below the threshold.  


## RD Types

RD designs come in two flavors: 

- Sharp: 
  - the probability that $D=1$ changes from 0 to 1 as the running variable crosses $c$. 
  - no one with $X<c$ gets treated and everyone with $X\geq c$ gets treated

- Fuzzy: 
  - the probability of treatment changes by some nonzero amount as the running variable crosses the threshold $c$,
  - the change in probability is less than 100 percentage points $\Rightarrow D_i$ is no longer a deterministic function of  $X_i$. 
  

## Sharp RD Set up: 


The probability that $D=1$ changes from 0 to 1 as the running variable crosses $c$. 

- no one with $X<c$ gets treated

- everyone with $X\geq c$ gets treated

- $\Rightarrow D_i$ is a deterministic function of $X_i: D_i=1$ if $(X_i\geq c)$.

- (or vice versa)

## Sharp RD Set up: 

 ![]("images\sharpRD.png")

## Sharp RD Set up: 

To estimate the causal effect of $D_i$ on some outcome $Y_i$, we simply take the difference in mean outcome on either side of $c$: 

\footnotesize
$$
\lim\limits_{x \rightarrow c}E[Y_i|X_i=x]-\lim\limits_{x \leftarrow c}E[Y_i|X_i=x]=\lim\limits_{x \rightarrow c}E[Y_i(1)|X_i=x]-\lim\limits_{x \leftarrow c}E[Y_i(0)|X_i=x]
$$

\normalsize

This estimates $\tau_{SRD}$, the causal effect for individuals with $X_i=c$:  

$$
\tau_{SRD}=E[Y_i(1)-Y_i(0)|X_i=c]
$$

## Sharp RD Assumption:


**The continuity assumption:**

\textbf{$E[Y_i(0)|X_i=x]$ and $E[Y_i(1)|X_i=x]$ are continuous in $x$.}

\bigskip
(Absent treatment, there would be no discontinuity in outcomes.)

## Sharp RD Assumption:


If the continuity assumption holds:

$$
\tau_{SRD}=\lim\limits_{x \rightarrow c}E[Y_i|X_i=x]-\lim\limits_{x \leftarrow c}E[Y_i|X_i=x]
$$


\bigskip
We can estimate $\tau_{SRD}$ as the difference between the two regression functions estimated in the **neighborhood** of $c$.

## Sharp RD designs: 

 ![]("images\sharpRD2.png"){width=75%}
 
## Sharp RD Simulation
 
You are the superintendent of a large school district. 
 
 Last year you made participation in small reading groups **mandatory** for all students whose 3rd grade reading score was 75 points or less.
 
 Your data includes the 3rd and 4th grade reading scores for all 5000 students in your school district. 
 
 **How did these reading groups affected student performance on their 4th grade reading tests?**
 
## Sharp RD Simulation
\small
```{r rdsharp1, echo=TRUE}

set.seed(7000)

sharp<-rnorm(5000, mean=80, sd=5)
sharp<-as.data.frame(sharp)

names(sharp)<-c("read3")
sharp$error<-rnorm(5000, mean=0, sd=5)
sharp$pe3<-rnorm(5000, mean=90, sd=4)
sharp$height<-rnorm(5000, mean=130, sd=15)
```

## Sharp RD Simulation
\small
```{r rdsharp1a, echo=TRUE}

sharp$treated<-0
sharp$treated[sharp$read3<=75]<-1

tau=10
#the DGP
sharp$read4<-(-6)+0.8*sharp$read3+tau*sharp$treated+sharp$error

sharp<-sharp[sharp$read3<78 & sharp$read3>72,]
 
```
 
 
 
## Fuzzy RD Set Up

Potentially more common than the sharp RD set ups. 
 
$D_i$ is no longer a deterministic function of  $X_i$. 

The probability of treatment changes by some nonzero amount as the running variable crosses the threshold $c$.

The change in probability is less than 100 percentage points. 
 

$$
0<\lim\limits_{x\rightarrow c}P(D_i=1|X_i=x)-\lim\limits_{x\leftarrow c}P(D_i=1|X_i=x)<1
$$

## Fuzzy RD Set Up

There are now two causal effects to be estimated: 

- the effect of crossing the threshold on the probability of treatment (which is 1 in the sharp RD) 

- the effect of crossing the threshold on the outcome. 

Formally, the fuzzy RD estimator is 
 
$$
\tau_{FRD}=\frac{\lim\limits_{x\rightarrow c} E[Y_i|X_i=x]-\lim\limits_{x\leftarrow c}E[Y_i|X_i=x]}{\lim\limits_{x\rightarrow c} E[D_i|X_i=x]-\lim\limits_{x\leftarrow c}E[D_i|X_i=x]}.
$$

**What should this remind you of?**

## Fuzzy RD IV

RD analog of an IV estimator:

- the instrument is an indicator for whether $X_i$ lies directly above $c$. 

- similar to how the IV estimator allowed us to recover the LATE estimate in an RCT.

## Fuzzy RD IV

In a fuzzy RD:
 
- the ITT group (say who have $X_i\geq c$ for example)

- the control group ($X_i<c$). 

Because we are in fuzzy land:

- if you are in the ITT group does not necessarily mean you get treated (there are never takers) 

- some in the control get treated (always takers).

- but there is a group of observations, the compliers, whose treatment status changes if they go from control to ITT (ie if they were moved across the threshold).

## Fuzzy RD IV

If I just compare the outcomes of those that are above and below the threshold ($\lim\limits_{x\rightarrow c} E[Y_i|X_i=x]-\lim\limits_{x\leftarrow c}E[Y_i|X_i=x]$) the effect is "diluted". **Why?**

- for many observations, crossing the threshold has no effect (since they are always or never takers). 

To get the LATE, scale treatment estimates by the change in probability of being treated ($\lim\limits_{x\rightarrow c} E[D_i|X_i=x]-\lim\limits_{x\leftarrow c}E[D_i|X_i=x]$).

$\Rightarrow$ the fuzzy RD design measures the average treatment effect for RD compliers at the threshold (the LATE),


$$
\tau_{FRD}=E[Y_i(1)-Y_i(0)|\text{unit }i\text{ is a complier and } X_i=c]. 
$$

## Fuzzy RD Simulation:
 

You are the superintendent of a large school district. 

Last year you **strongly encouraged** students to participate in small reading groups if their 3rd grade reading score fell below 75 points.

Your data includes the 3rd and 4th grade reading scores for all 5000 students in your school district. 

 **How did these reading groups affected student performance on their 4th grade reading tests?**


## Fuzzy RD Simulation:

 \tiny
```{r rdfuzzy1, echo=TRUE}


set.seed(2000)

fuzzy<-rnorm(5000, mean=80, sd=5)
fuzzy<-as.data.frame(fuzzy)

names(fuzzy)<-c("read3")
fuzzy$error<-rnorm(5000, mean=0, sd=5)
fuzzy$pe3<-rnorm(5000, mean=90, sd=4)
fuzzy$height<-rnorm(5000, mean=130, sd=15)

```

## Fuzzy RD Simulation:
\tiny
```{r rdfuzzy1b, echo=TRUE}

fuzzy$lowprob<-rbinom(5000,1,0.3)
fuzzy$highprob<-rbinom(5000,1,0.8)
fuzzy$treated<-NA
fuzzy$treated[fuzzy$read3>75]<-fuzzy$lowprob[fuzzy$read3>75]
fuzzy$treated[fuzzy$read3<=75]<-fuzzy$highprob[fuzzy$read3<=75]

tau=10

#the DGP
fuzzy$read4<-(-6)+0.8*fuzzy$read3+tau*fuzzy$treated+fuzzy$error

fuzzy<-fuzzy[fuzzy$read3<78 & fuzzy$read3>72,]

```
 
 

## RD and External Validity

Notice the conditioning statements in our treatment estimators. 

- With fuzzy RD's, we are estimating effects on compliers 
 
- We focus on observations that are in the neighborhood of the threshold. **Why?**
  - implicitly we are assuming that an observation falling just above or just below the threshold is effectively random 
  - $\Rightarrow$ we can measure a LATE that is valid around $c$ 
  - observations far below and far above the threshold likely differ from each other in observable and unobservable ways. 
  
## RD and External Validity

Because of these conditions, RD estimates are:

- inherently localized since the effects are estimated for a sub population where their $X_i$ is in the neighborhood of $c$.

- have a relatively high degree of internal validity,

- it is important to think about their external validity:  
  - treatment effects could be quite different for observation where $X_i$ is quite different from $c$. 
  
 
 
## RD Graphs

Key to a good RD project is the graphical analysis (statistical results really take a back seat). 

A discontinuous change in treatment and outcomes (if $\tau\neq 0$) should be visible as $X_i$ crosses the threshold $c$.

Failure to show visually perceptible breaks at $c$ challenges the credibility of the approach (regardless of the regression results). 

A break that is visually perceptible will almost surely be statistically significant. 

## RD Graphs

A simple scatterplot of your data is unlikely to reveal the patterns you wish to illustrate. 

The key RD graphs are histogram-type plot that presents the average value of:

- the outcome 

- treatment status 

- covariates 

at evenly spaced values of the running variable. 

## RD Graphs

Gernerating these plots requires choosing two key parameters:

- the binwidth, $h$, 

- the number of bins shown to the left and right of the threshold value, $K_0$ and $K_1$. 

Once these choices are made, construct:

- $K_0$ evenly spaced bins of width $h$ below the threshold value 

- $K_1$ evenly spaced bins of width $h$ above the threshold value

- (avoid having any bin crossing the threshold value $c$). 


## RD Treatment status graph

RD papers often include a graph that plots treatment by the running variable. 

We expect to see a visually perceptible discontinuity in the probability of treatment as $X$ crosses the threshold. 

After constructing the bins described above, calculate $\bar{D}_k$, the average treatment level in the bin

$$
\bar{D}_k=\frac{1}{N_k}\sum_{i=1}^ND_i*1(b_k<X_i\leq b_{k+1}).
$$ 

Plot these values against the midpoint of each of the bins. 

## Sharp RD: Treatment status graph


In a sharp RD, $\bar{D}_k$ should be either 0 or 1. 

## Sharp RD: Treatment status graph Simulation
\tiny
```{r sharp2, echo=TRUE}

#I will break up the data into 60 bins (30 above and 30 below the threshold)
cuts<-c(72,72.1,72.2,72.3,72.4,72.5,72.6,72.7,72.8,72.9,73,
        73.1,73.2,73.3,73.4,73.5,73.6,73.7,73.8,73.9,74,
        74.1,74.2,74.3,74.4,74.5,74.6,74.7,74.8,74.9,75,
        75.1,75.2,75.3,75.4,75.5,75.6,75.7,75.8,75.9,76,
        76.1,76.2,76.3,76.4,76.5,76.6,76.7,76.8,76.9,77,
        77.1,77.2,77.3,77.4,77.5,77.6,77.7,77.8,77.9,78)
midpoints<-cuts[2:61]-0.05

sharp$bins <- cut(sharp$read3, 
                  breaks=cuts, 
                  include.lowest=TRUE, 
                  right=FALSE, 
                  labels=midpoints)


sharp_mean<-sharp %>%
    group_by(bins) %>%
    dplyr::summarize(outbinmean = mean(read4, na.rm=TRUE),
                     treatbinmean=mean(treated, na.rm=TRUE), 
                     pebinmean=mean(pe3, na.rm=TRUE),
                     heightbinmean=mean(height, na.rm=TRUE), numb=n())

sharp_mean$bins<-as.numeric(as.character(sharp_mean$bins))

plot1shp<-ggplot(sharp_mean, aes(x=bins, y=treatbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)

```


## Sharp RD: Treatment status graph Simulation

```{r sharp2b, echo=TRUE}

plot1shp

```


## Fuzzy RD: Treatment status graph


In a fuzzy RD, $\bar{D}_k$ can take on many possible values. 

This plot should show that there is a visual discontinuity in the probability of getting treated at the threshold $c$.

This graph is equivalent to the first stage in an IV analysis: It shows that we have found a tool that generates some random variation we can leverage to estimate unbiased treatment effects. 

## Fuzzy RD: Treatment status graph Simulation

\tiny
```{r fuzzy2, echo=TRUE}

#I will break up the data into 60 bins (30 above and 30 below the threshold)

cuts<-c(72,72.1,72.2,72.3,72.4,72.5,72.6,72.7,72.8,72.9,73,
        73.1,73.2,73.3,73.4,73.5,73.6,73.7,73.8,73.9,74,
        74.1,74.2,74.3,74.4,74.5,74.6,74.7,74.8,74.9,75,
        75.1,75.2,75.3,75.4,75.5,75.6,75.7,75.8,75.9,76,
        76.1,76.2,76.3,76.4,76.5,76.6,76.7,76.8,76.9,77,
        77.1,77.2,77.3,77.4,77.5,77.6,77.7,77.8,77.9,78)
midpoints<-cuts[2:61]-0.05

fuzzy$bins <- cut(fuzzy$read3, 
                  breaks=cuts, 
                  include.lowest=TRUE, 
                  right=FALSE, 
                  labels=midpoints)
        

fuzzy_mean<-fuzzy %>%
    group_by(bins) %>%
    dplyr::summarize(outbinmean = mean(read4, na.rm=TRUE),
                     treatbinmean=mean(treated, na.rm=TRUE),
                     pebinmean=mean(pe3, na.rm=TRUE),
                     heightbinmean=mean(height, na.rm=TRUE), numb=n())

fuzzy_mean$bins<-as.numeric(as.character(fuzzy_mean$bins))

plot1fuz<-ggplot(fuzzy_mean, aes(x=bins, y=treatbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)
```

## Fuzzy RD: Treatment status graph Simulation

```{r fuzzy2a, echo=TRUE}

plot1fuz

```



## Outcome Graphs

The main course of an RD paper is a plot of the outcome by the running variable. 

If $\tau\neq0$, we expect to see a discontinuity here too. 

Plotting this graph requires calculating, $\bar{D}_k$, the average outcome in each bin

$$
\bar{Y}_k=\frac{1}{N_k}\sum_{i=1}^NY_i*1(b_k<X_i\leq b_{k+1})
$$

and plotting these values against the midpoint of each of the bins.

## Outcome Graphs

A visual break at $c$

- $\Rightarrow$ crossing $c$ has a significant effect on the outcome,

- $\Rightarrow$ the treatment has a significant effect on the outcome. This graph is the equivalent of the reduced form in an IV analysis. 


## Outcome Graphs: Robustness

You should also look for other discontinuities of similar (or greater) magnitude at other values of $X_i$.

If there discontinuities for no clear reason, the research design is called into question - effectively we have detected a violation of Assumption 1 (smoothness in expected potential outcomes). 


## Outcome Graphs: Sharp

\tiny
```{r sharp3a, echo=TRUE}

plot2shp<-ggplot(sharp_mean, aes(x=bins, y=outbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)

```

## Outcome Graphs: Sharp

\tiny
```{r sharp3b}

plot2shp
```

## Outcome Graphs: Fuzzy


```{r fuz3a, echo=TRUE}


plot2fuz<-ggplot(fuzzy_mean, aes(x=bins, y=outbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot2fuz


```


## Outcome Graphs: Fuzzy

```{r fuz3b}

plot2fuz

```


## Robustness Graphs: Covariates

It is common to plot covariates that may be related to the outcome but should not be affected by the treatment. 

As above, we calculate $\bar{Z}_i$ where 
$$
\bar{Z}_k=\frac{1}{N_k}\sum_{i=1}^NZ_i*1(b_k<X_i\leq b_{k+1})
$$
is plotted against the midpoint of each bin.


If the research design is valid there should not be any discontinuity in $\bar{Z}_k$ as the running variable crosses the threshold $c$. 

This is equivalent to a balance check across the threshold- you are checking that the treated and un-treated groups are similar.


## Robustness Graphs: Covariates sharp

\tiny
```{r sharp4a, echo=TRUE}

plot3shp<-ggplot(sharp_mean, aes(x=bins, y=pebinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot3shp

```


## Robustness Graphs: Covariates sharp

\tiny
```{r sharp4b, echo=TRUE}


plot4shp<-ggplot(sharp_mean, aes(x=bins, y=heightbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot4shp


```


## Robustness Graphs: Covariates fuzzy

\tiny

```{r fuz4a}


plot3fuz<-ggplot(fuzzy_mean, aes(x=bins, y=pebinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot3fuz
```

## Robustness Graphs: Covariates fuzzy
\tiny
```{r fuz4b}

plot4fuz<-ggplot(fuzzy_mean, aes(x=bins, y=heightbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot4fuz

```


## Robustness Graphs: Density of the Running Variable

It is also common to plot the density of the running variable. 

For each bin, you calculate
$$
N_k=\sum_{i=1}^N1(b_k<X_i\leq b_{k+1})
$$
and plot these against the midpoint of the bin. 

A concern in RD is that individuals may "game" the assignment rule: they manipulate their $X_i$ to place themselves just above (below) $c$. 

This sorting would create selection bias and bias our estimate of $\tau$.

If units are manipulating $X_i$ around $c$, we will see a discontinuity in the distribution of $X_i$ as it crosses $c$. 

If the distribution of $X_i$ is smooth as it crosses $c$, then it's unlikely that individuals are gaming the assignment mechanism. 

## Robustness Graphs: Density of the Running Variable

Example:

- consider a scholarship if test scores fall above a certain threshold $c$. Shrewd students could retake the test many times until they pass the threshold.

- If a researcher uses an individuals maximum test score as the running variable, motivated individuals who retake the test many times are more likely to fall just above the threshold, then just below it.

- this group of observations is selected and no longer directly comparable to the observations that fall directly below the threshold. 


## Robustness Graphs: Density of the Running Variable (Sharp)
\tiny
```{r sharp5, echo=TRUE}

plot5shp<-ggplot(sharp_mean, aes(x=bins, y=numb))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot5shp

```

## Robustness Graphs: Density of the Running Variable (Fuzzy)

\tiny
```{r fuz5, echo=TRUE}

plot5fuz<-ggplot(fuzzy_mean, aes(x=bins, y=numb))+ 
         geom_point()+
         geom_vline(xintercept = 75)
plot5fuz

```



## RD Estimation

RD estimations can be done quite easily in a regression framework.

Step 1: Selecting a bandwidth, $h$, that will determine the regression sample on either side of the threshold point $c$.

- bandwith selection involves thinking about the tradeoff between sample size and group comprability

- there is an econometric literature that discusses methods to choose the optimal bandwidth 

- in practice this choice is more art than science and many papers make this choice fairly arbitrarily

- it is generally good practice to check that results are not sensitive to the choice of bandwidth


## RD Estimation: Sharp

Fit a linear regression on either side of the threshold point for the samples with $X-i\in (c-h,c)$ and $X_i[c,c+h)]$.

Estimating some version (you can include covariates) of the following specification,

$$
Y_i=\alpha+\tau D-i+\beta(X_i-c)+\gamma (X_i-c)*D_i+u_i \text{ for }  c-h<X_i\leq c+h. 
$$

With this estimation strategy, $\hat{\tau}_{SRD}$ will estimate the treatment effect for units right at the threshold. 

## RD Estimation: Sharp
\tiny
```{r shp6,echo=TRUE, results="asis"}

sharp$runminc<-sharp$read3-75
shpestim<-felm(read4~treated+runminc+treated*runminc, sharp)

stargazer(shpestim, type="latex", header=FALSE)

```

## RD Estimation: Sharp

It is helpful to see how the coefficients estimated above translate to the RD graph. 

ADD Stylized graph and top hat question

## RD Estimation: Sharp

It is helpful to see how the coefficients estimated above translate to the RD graph. 

\tiny
```{r shp7, echo=TRUE}

sharp_mean$runminc<-sharp_mean$bins-75

plot6shp<-ggplot(sharp_mean, aes(x=runminc, y=outbinmean))+ 
         geom_point()+
         geom_vline(xintercept = 0)+
         geom_segment(aes(x = 0, xend = 3, 
                          y = shpestim$coefficients[1],
                          yend = shpestim$coefficients[1]
                                 +3*shpestim$coefficients[3]))+
         geom_segment(aes(x = -3, xend = 0,
                          y = shpestim$coefficients[1]
                              + shpestim$coefficients[2]
                              +(-3*( shpestim$coefficients[3]+ shpestim$coefficients[4])), 
                          yend = shpestim$coefficients[1]
                              + shpestim$coefficients[2]))+
          #adding some labeling for course notes:
          annotate("text", x = 0.75, y = 64.8,
                   label = "Intercept~is~alpha~+~tau" ,parse = TRUE)+
          annotate("text", x = -0.6, y = 54, 
                   label = "Intercept~is~alpha" ,parse = TRUE)+
          annotate("text", x = -2, y = 64,
                   label = "Slope~is~beta~+~gamma" ,parse = TRUE)+
          annotate("text", x = 2, y = 54, 
                   label = "Slope~is~beta" ,parse = TRUE)+
          annotate("text", x = -1, y = 58, 
                   label = "TREATED" ,parse = TRUE)+
          annotate("text", x = 1, y = 58, 
                   label = "UNTREATED" ,parse = TRUE) 
```

## RD Estimation: Sharp

$$
Y_i=\alpha+\tau D-i+\beta(X_i-c)+\gamma (X_i-c)*D_i+u_i \text{ for }  c-h<X_i\leq c+h. 
$$

\tiny
```{r shp7b, echo=TRUE}

plot6shp

```


## RD Estimation: Fuzzy


In the fuzzy RD design, we have two effects to estimate: 

- the effect of crossing the threshold on the treatment (the "first stage") 

- the effect of crossing the threshold on the outcome (the "reduced form"). 

We apply the same methodology as in earlier IV's to estimate the effect of crossing the threshold on $Y_i$ and the effect of crossing the threshold on $D_i$. 

## RD Estimation: Fuzzy

For the sample with $c-h<X_i\leq c+h$ we run some version (you can include covariates) of the following regressions,
$$
Y_i=\pi_0+\pi_1D_i+\pi_2(X_i-c)+\pi_3(X_i-c)*D_i+u_i 
$$
where the first stage is given by
$$
D_i=\gamma_0+\gamma_1Z_i+\gamma_2(X_i-c)+\gamma_3(X_i-c)*Z_i+v_i
$$
where $Z_i=1(X_i\geq c)$.

## RD Estimation: Fuzzy

The fuzzy RD estimator is then 

$$
\hat{\tau}_{FRD}=\frac{\hat{\pi}_1}{\hat{\gamma}_1}.
$$
The FRD estimator is the ratio of the reduced form and the first stage estimates

i.e. the effect of crossing the discontinuity threshold on the outcome, scaled by the effect of crossing the discontinuity threshold on the probability of treatment. 



## RD Estimation: Fuzzy

\tiny
```{r fuz7, results="asis", echo=TRUE}

fuzzy$runminc<-fuzzy$read3-75

#first stage
fuzzy$ittgroup<-0
fuzzy$ittgroup[fuzzy$read3<=75]<-1

fuzfs<-felm(treated~ittgroup+runminc+ittgroup*runminc,fuzzy)

#reduced form
fuzrf<-felm(read4~ittgroup+runminc+ittgroup*runminc,fuzzy)


fuzzy$interedog<-fuzzy$treated*fuzzy$runminc
fuzzy$interinst<-fuzzy$ittgroup*fuzzy$runminc
#IV
fuziv<-felm(read4~runminc|0|(treated|interedog~ittgroup+runminc+interinst),fuzzy)
```

## RD Estimation: Fuzzy
\tiny
```{r fuz7b, results="asis", echo=TRUE}

stargazer(fuzfs, fuzrf, fuziv, type="latex", header=FALSE)

```

## RD Estimation: Fuzzy

Note: you will not be able to plot the "scaled" treatment effect as the graphs are limited to the graphical equivalent of the first stage and the reduced form estimates. 






